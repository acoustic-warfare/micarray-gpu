{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import sounddevice\n",
    "# import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from Audio_data import Audio_data\n",
    "from Matrix_array import Matrix_array\n",
    "from Audio_source import Audio_source\n",
    "from Color_map import Color_map\n",
    "import config\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "c = 340                     # propagation speed of sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antenna_setup():\n",
    "    r_a1 = config.r_a1      # coordinate position of origin of array1\n",
    "    r_a2 = config.r_a2      # coordinate position of origin of array2\n",
    "    r_a3 = config.r_a3      # coordinate position of origin of array3\n",
    "    r_a4 = config.r_a4      # coordinate position of origin of array4\n",
    "    uni_distance = config.distance\n",
    "    row_elements = config.rows\n",
    "    column_elements = config.columns\n",
    "\n",
    "    # array_matrix_1, array_matrix_2, array_matrix_3, array_matrix_4 below can be generated in parallell\n",
    "    array_matrix_1 = Matrix_array(\n",
    "        r_a1, uni_distance, row_elements, column_elements)\n",
    "    array_matrix_2 = Matrix_array(\n",
    "        r_a2, uni_distance, row_elements, column_elements)\n",
    "    array_matrix_3 = Matrix_array(\n",
    "        r_a3, uni_distance, row_elements, column_elements)\n",
    "    array_matrix_4 = Matrix_array(\n",
    "        r_a4, uni_distance, row_elements, column_elements)\n",
    "\n",
    "    # array_matrices contains the current active arrays that should be used (currently only array1 and array2)\n",
    "    array_matrices = np.array([array_matrix_1], dtype=object)\n",
    "\n",
    "    sub_arrays = len(array_matrices)\n",
    "\n",
    "    for array in range(sub_arrays):\n",
    "        plt.title('Array setup')\n",
    "        plt.scatter(array_matrices[array].get_r_prime()[\n",
    "                    0, :], array_matrices[array].get_r_prime()[1, :])\n",
    "\n",
    "    return array_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_array_signals(matrix_array, sources, t):\n",
    "    r_prime = matrix_array.get_r_prime()\n",
    "    Audio_signal = np.zeros((len(t), len(r_prime[0, :])))\n",
    "\n",
    "    for sample in range(len(t)):\n",
    "        # print stuff so user know how many samples that have been generated\n",
    "        if (sample+1 in np.linspace(0, len(t), 11)) or (sample == 0):\n",
    "            # print stuff so user know how many samples that have been generated\n",
    "            print(sample+1)\n",
    "        for mic in range(len(r_prime[0, :])):\n",
    "            x_i = r_prime[0, mic]\n",
    "            y_i = r_prime[1, mic]\n",
    "            temp_signal_sample = 0\n",
    "            for source in range(len(sources)):\n",
    "                if (sources[source].get_t_start() < t[sample]) and (t[sample] < sources[source].get_t_end()):\n",
    "                    frequencies_ps = sources[source].get_frequency()\n",
    "                    theta_source = sources[source].get_theta()\n",
    "                    phi_source = sources[source].get_phi()\n",
    "                    rho_soruce = sources[source].get_rho()\n",
    "                    for freq_ind in range(len(frequencies_ps)):\n",
    "                        k = 2*math.pi*frequencies_ps[freq_ind]/c\n",
    "                        r_1 = np.array([x_i, y_i, 0])\n",
    "                        r_2 = rho_soruce * r_vec(theta_source, phi_source)\n",
    "                        norm_coeff = np.linalg.norm(r_2-r_1)\n",
    "                        phase_offset = -k*norm_coeff\n",
    "                        element_amplitude = 1/norm_coeff\n",
    "                        temp_signal_sample += element_amplitude * \\\n",
    "                            math.sin(\n",
    "                                2*math.pi * frequencies_ps[freq_ind] * t[sample] + phase_offset)\n",
    "            Audio_signal[sample, mic] = temp_signal_sample\n",
    "    return Audio_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def r_vec(theta, phi):\n",
    "    r = np.array([(math.sin(theta)*math.cos(phi)),\n",
    "                 math.sin(theta)*math.sin(phi), math.cos(theta)])\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibration_weights(array, elements, f_bands):\n",
    "    # placeholder function, to be completed later\n",
    "    # function should load calibration weights form file\n",
    "    # returns matrix with calibration weightsfor all microphones, at all calibration frequencies\n",
    "    weights = np.ones((f_bands, elements))\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_listening_improved(array_audio_signals, array_matrices, theta, phi, adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays):\n",
    "    x_factor = math.sin(theta) * math.cos(phi)\n",
    "    y_factor = math.sin(theta) * math.sin(phi)\n",
    "    audio_out = np.zeros((samples, 1))\n",
    "\n",
    "    for array in range(sub_arrays):\n",
    "        #print('array: '+str(array+1))               # print for user\n",
    "        r_prime = array_matrices[array].get_r_prime()\n",
    "        audio_signals = array_audio_signals[array].get_audio_signals()\n",
    "\n",
    "        elements = config.rows*config.columns\n",
    "        print('freq_ind: ', end=' ')\n",
    "        for freq_ind in range(len(filter_coefficients[:, 0])):\n",
    "            print(str(freq_ind+1), end=' ')  # print for user\n",
    "            # filter coefficient for the current band\n",
    "            b = filter_coefficients[freq_ind, :]\n",
    "            frequency = frequency_bands[freq_ind]   # center frequency\n",
    "            k = 2*math.pi*frequency/c               # the narrowband frequency\n",
    "            ny = frequency/f_sampling               # normalized frequency\n",
    "            weights = adaptive_weight_matrix[weight_index(frequency)-1, :]\n",
    "\n",
    "            audio_temp = np.zeros((samples, 1))\n",
    "            mic_data = np.zeros((samples, 1))\n",
    "            #print('\\t mic_ind:', end=' ')           # print stuff for user\n",
    "            for mic_ind in range(elements):\n",
    "                #print(str(mic_ind+1), end=' ')      # print stuff for user\n",
    "                if weights[mic_ind] == 1:\n",
    "                    audio_temp[:, 0] = calibration_weights[freq_ind, mic_ind] * \\\n",
    "                        signal.lfilter(b, 1.0, audio_signals[:, mic_ind])\n",
    "                    phase_shift_value = -k * \\\n",
    "                        (r_prime[0, mic_ind] * x_factor +\n",
    "                         r_prime[1, mic_ind]*y_factor)\n",
    "\n",
    "                    #   Sum the individually shifted data from the atnenna elements as well as weight them with\n",
    "                    #   appropriate weight.\n",
    "                    mic_data += weights[mic_ind] * \\\n",
    "                        phase_shift(audio_temp, ny, phase_shift_value)\n",
    "\n",
    "            norm_coeff = 1/sum(weights)\n",
    "            audio_out += mic_data * norm_coeff\n",
    "    return audio_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "return_queue = manager.dict()\n",
    "\n",
    "backend_type = multiprocessing.Process\n",
    "\n",
    "\n",
    "def kernel(freq_ind, elements, audio_signals, r_prime, x_factor, y_factor, array_matrices, theta, phi, adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays, return_queue=None):\n",
    "    # print(freq_ind, elements, audio_signals, r_prime, x_factor, y_factor, array_matrices, theta, phi,\n",
    "    #       adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays)\n",
    "    # return\n",
    "    try:\n",
    "        b = filter_coefficients[freq_ind, :]\n",
    "        frequency = frequency_bands[freq_ind]   # center frequency\n",
    "        k = 2*math.pi*frequency/c               # the narrowband frequency\n",
    "        ny = frequency/f_sampling               # normalized frequency\n",
    "        weights = adaptive_weight_matrix[weight_index(frequency)-1, :]\n",
    "\n",
    "        audio_temp = np.empty((samples, 1)) # Changed to empty from zeros\n",
    "        mic_data = np.zeros((samples, 1))\n",
    "        #print('\\t mic_ind:', end=' ')           # print stuff for user\n",
    "        # internal_return_queue = manager.dict()\n",
    "        # def internal_kernel(mic_ind, internal_return_queue=None):\n",
    "        #     if weights[mic_ind] == 1:\n",
    "        #         audio_temp[:, 0] = calibration_weights[freq_ind, mic_ind] * \\\n",
    "        #             signal.lfilter(b, 1.0, audio_signals[:, mic_ind])\n",
    "        #         phase_shift_value = -k * \\\n",
    "        #             (r_prime[0, mic_ind] * x_factor +\n",
    "        #                 r_prime[1, mic_ind]*y_factor)\n",
    "\n",
    "        #         internal_return_queue[mic_ind] = weights[mic_ind] * \\\n",
    "        #             phase_shift(audio_temp, ny, phase_shift_value)\n",
    "        \n",
    "        for mic_ind in range(elements):\n",
    "            #print(str(mic_ind+1), end=' ')      # print stuff for user\n",
    "            if weights[mic_ind] == 1:\n",
    "                audio_temp[:, 0] = calibration_weights[freq_ind, mic_ind] * \\\n",
    "                    signal.lfilter(b, 1.0, audio_signals[:, mic_ind])\n",
    "                phase_shift_value = -k * \\\n",
    "                    (r_prime[0, mic_ind] * x_factor +\n",
    "                        r_prime[1, mic_ind]*y_factor)\n",
    "\n",
    "                #   Sum the individually shifted data from the atnenna elements as well as weight them with\n",
    "                #   appropriate weight.\n",
    "                mic_data += weights[mic_ind] * \\\n",
    "                    phase_shift(audio_temp, ny, phase_shift_value)\n",
    "\n",
    "    \n",
    "\n",
    "        norm_coeff = 1/sum(weights)\n",
    "        return_queue[freq_ind] = mic_data * norm_coeff\n",
    "        print(f\"Process: {freq_ind} done!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return_queue[freq_ind] = None\n",
    "        print(f\"Process: {freq_ind} Error!\")\n",
    "\n",
    "\n",
    "def old_kernel(freq_ind, mic_ind, elements, audio_signals, r_prime, x_factor, y_factor, array_matrices, theta, phi, adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays, return_queue=None):\n",
    "    \n",
    "    frequency = frequency_bands[freq_ind]   # center frequency\n",
    "    \n",
    "    weights = adaptive_weight_matrix[weight_index(frequency)-1, :]\n",
    "    if weights[mic_ind] != 1:\n",
    "        return\n",
    "\n",
    "    b = filter_coefficients[freq_ind, :]\n",
    "    k = 2*math.pi*frequency/c               # the narrowband frequency\n",
    "    ny = frequency/f_sampling               # normalized frequency\n",
    "\n",
    "    audio_temp = np.empty((samples, 1))  # Changed to empty from zeros\n",
    "    mic_data = np.zeros((samples, 1))\n",
    "\n",
    "    \n",
    "    audio_temp[:, 0] = calibration_weights[freq_ind, mic_ind] * \\\n",
    "        signal.lfilter(b, 1.0, audio_signals[:, mic_ind])\n",
    "    phase_shift_value = -k * \\\n",
    "        (r_prime[0, mic_ind] * x_factor +\n",
    "            r_prime[1, mic_ind]*y_factor)\n",
    "\n",
    "    #   Sum the individually shifted data from the atnenna elements as well as weight them with\n",
    "    #   appropriate weight.\n",
    "    mic_data += weights[mic_ind] * \\\n",
    "        phase_shift(audio_temp, ny, phase_shift_value)\n",
    "\n",
    "def listening_improved(array_audio_signals, array_matrices, theta, phi, adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays):\n",
    "    x_factor = math.sin(theta) * math.cos(phi)\n",
    "    y_factor = math.sin(theta) * math.sin(phi)\n",
    "    audio_out = np.zeros((samples, 1))\n",
    "\n",
    "    for array in range(sub_arrays):\n",
    "        r_prime = array_matrices[array].get_r_prime()\n",
    "        audio_signals = array_audio_signals[array].get_audio_signals()\n",
    "\n",
    "        elements = config.rows*config.columns\n",
    "        myjobs_old = [freq_ind for freq_ind in range(len(filter_coefficients[:, 0]))]\n",
    "        #myjobs = [0, 1]\n",
    "        myjobs = []\n",
    "        for k in range(len(myjobs_old)):\n",
    "            for i in range(elements):\n",
    "                myjobs.append((k,i))\n",
    "        myjobs = [0 for _ in range(len(myjobs_old))]\n",
    "\n",
    "        # print(jobs)\n",
    "        # freq_ind = jobs[0]\n",
    "        # b = filter_coefficients[freq_ind, :]\n",
    "        # print(b)\n",
    "\n",
    "        # return\n",
    "        import threading\n",
    "        \n",
    "        #backend_type = threading.Thread\n",
    "\n",
    "        jobs = []\n",
    "        for freq_ind in myjobs:\n",
    "            p = backend_type(\n",
    "                target=kernel, args=(freq_ind, elements, audio_signals, r_prime, x_factor, y_factor, array_matrices, theta, phi, adaptive_weight_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays), kwargs=dict(return_queue=return_queue))\n",
    "            jobs.append(p)\n",
    "        \n",
    "        for p in jobs:\n",
    "            p.start()\n",
    "\n",
    "        for proc in jobs:\n",
    "            proc.join()\n",
    "\n",
    "    # return color_maps_complete\n",
    "    return return_queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adaptive_array_config_matrix(matrix_array):\n",
    "    # Creates the weight matrix\n",
    "    row_elements = matrix_array.get_row_elements()\n",
    "    column_elements = matrix_array.get_row_elements()\n",
    "\n",
    "    weight_matrix = np.zeros((7, row_elements*column_elements))\n",
    "\n",
    "    for mode in range(1, config.modes+1):\n",
    "        weight = np.zeros((1, row_elements*column_elements))\n",
    "        row_lim = math.ceil(row_elements/mode)\n",
    "        column_lim = math.ceil(column_elements/mode)\n",
    "        for i in range(row_lim):\n",
    "            for j in range(column_lim):\n",
    "                # this calculation could be wrong thanks to matlab and python index :))\n",
    "                element_index = (mode*i*row_elements + mode*j)\n",
    "                weight[0, element_index] = 1\n",
    "        weight_matrix[mode-1, :] = weight\n",
    "    return weight_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_index(frequency):\n",
    "    # calculates what mode to use, depending on the wavelength of the signal\n",
    "    uni_distance = config.distance              # distance between elements\n",
    "    # relative wavelength to distance between microphone elements\n",
    "    wavelength_rel = frequency*uni_distance/c\n",
    "\n",
    "    if wavelength_rel > 0.1581:\n",
    "        mode = 1\n",
    "    elif (wavelength_rel <= 0.156) and (wavelength_rel > 0.0986):\n",
    "        mode = 3\n",
    "    elif (wavelength_rel <= 0.0986) and (wavelength_rel > 0.085):\n",
    "        mode = 5\n",
    "    elif (wavelength_rel <= 0.085) and (wavelength_rel > 0.07):\n",
    "        mode = 6\n",
    "    else:\n",
    "        mode = 7\n",
    "    return mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def phase_shift(x, ny, phase):\n",
    "    #   Input signal x\n",
    "    #\n",
    "    #   Output signal y\n",
    "    #\n",
    "    #   if x = cos(n*2*pi*ny), then y = cos(n*2*pi*ny + phase)\n",
    "    #\n",
    "    x_length = len(x)\n",
    "    y = np.zeros((x_length, 1))\n",
    "\n",
    "    for i in range(x_length-1):\n",
    "        y[i] = math.cos(phase) * x[i] + math.sin(phase) / \\\n",
    "            (2*math.pi*ny)*(x[i+1]/2 - x[i-1]/2)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_filter_coefficients(f_sampling, frequency_bands):\n",
    "    scale_factor = config.scale_factor\n",
    "    f_bands_N = config.f_bands_N\n",
    "    filter_order = config.filter_order\n",
    "    f_coefficients = np.zeros((f_bands_N, filter_order))\n",
    "    for freq_ind in range(config.f_bands_N):\n",
    "        nu_0 = 2*frequency_bands[freq_ind]/f_sampling\n",
    "        cut_off = [nu_0 - nu_0/scale_factor, nu_0 + nu_0/scale_factor]\n",
    "        b = signal.firwin(filter_order, cut_off, window=\"hamming\",\n",
    "                          pass_zero=False)  # filter coefficients\n",
    "        f_coefficients[freq_ind, :] = b\n",
    "    return f_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    initial = config.initial_values\n",
    "    # Load recorded data from file\n",
    "    path = Path('/home/batman/BatSignal/data/studion1507/' + filename + '.txt')\n",
    "    data = np.loadtxt(open(path, 'rb'), delimiter=',')\n",
    "\n",
    "    # Get sampling frequency\n",
    "    f_sampling = data[0, 0]\n",
    "\n",
    "    # take out only the values of the microphones (column 2:66)\n",
    "    # and data after the initial startup (rows initial:end)\n",
    "    data = data[initial:, 2:66]\n",
    "    return Audio_data(data), int(f_sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def play_sound(sound_signal, f_sampling):\n",
    "    # plays sound, and writes audio to .wav file\n",
    "    scaled_signal = sound_signal/np.max(np.abs(sound_signal))  # Scaled signal\n",
    "    sounddevice.play(scaled_signal, f_sampling, blocking=True)\n",
    "\n",
    "    sf.write(\"test.wav\", scaled_signal, int(f_sampling), 'PCM_24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "# f_sampling, t_start, t_end, away_distance are user defined variables\n",
    "f_sampling = 16000# config.f_sampling                      # sampling frequency in Hz\n",
    "t_start = config.t_start                            # start time of simulation\n",
    "t_end = config.t_end                                # end time of simulation\n",
    "t_total = t_end - t_start                           # total simulation time\n",
    "t = np.linspace(t_start, t_end, t_total*f_sampling)  # time vector\n",
    "\n",
    "# distance between the array and sources\n",
    "away_distance = config.away_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set up arrays\n",
    "array_matrices = antenna_setup()\n",
    "sub_arrays = len(array_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and place out sources\n",
    "source1 = Audio_source(config.f_start1, config.f_end1, config.f_res1,\n",
    "                       config.theta_deg1, config.phi_deg1, config.away_distance, config.t_start1, config.t_end1)\n",
    "source2 = Audio_source(config.f_start2, config.f_end2, config.f_res2,\n",
    "                       config.theta_deg2, config.phi_deg2, config.away_distance, config.t_start2, config.t_end2)\n",
    "sources = np.array([source1, source2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Memory: array_audio_signals.npy\n"
     ]
    }
   ],
   "source": [
    "# AUDIO SIGNALS\n",
    "if True:\n",
    "    filename = \"array_audio_signals.npy\"\n",
    "    try:\n",
    "        # array_audio_signals = np.load(filename)\n",
    "        array_audio_signals = np.load(filename, allow_pickle=True)\n",
    "        print(\"Loading from Memory: \" + filename)\n",
    "    except:\n",
    "        print(\"Creating data\")\n",
    "\n",
    "        # Create and place out sources\n",
    "        # source1 and source2 below can be generated in parallell\n",
    "        source1 = Audio_source(config.f_start1, config.f_end1, config.f_res1,\n",
    "                               config.theta_deg1, config.phi_deg1, config.away_distance, config.t_start1, config.t_end1)\n",
    "        source2 = Audio_source(config.f_start2, config.f_end2, config.f_res2,\n",
    "                               config.theta_deg2, config.phi_deg2, config.away_distance, config.t_start2, config.t_end2)\n",
    "        sources = np.array([source1])\n",
    "\n",
    "        # GENERATE AUDIO SIGNAL\n",
    "        # will only be used to emulate data, this will not be used when the algoritm runs with real data\n",
    "        array_audio_signals = np.zeros((sub_arrays), dtype=object)\n",
    "        print('Number of samples generated (of '+str(f_sampling*t_total)+'):')\n",
    "        for array in range(sub_arrays):  # PARALLELL\n",
    "            # generate the audio signals on each array-element for each sub-array\n",
    "            temp_signal = generate_array_signals(\n",
    "                array_matrices[array], sources, t)\n",
    "            array_audio_signals[array] = Audio_data(temp_signal)\n",
    "            print('Audio signal for array '+str(array+1)+' generated')\n",
    "\n",
    "        np.save(filename, array_audio_signals)\n",
    "\n",
    "# elif config.audio_signals == 'recorded':\n",
    "#     filename = 'studion_A2_sound_0deg.bin'\n",
    "#     print('Loading recorded data: '+filename)\n",
    "#     array_audio_signals = np.zeros((sub_arrays), dtype=object)\n",
    "#     array_audio_signals[0], f_sampling = load_data(filename)\n",
    "# else:\n",
    "#     array_audio_signals = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play recorded sound from original signal from one mic (mic 7)\n",
    "original_signal = array_audio_signals[0].get_audio_signals()[:, 7]\n",
    "#play_sound(original_signal, f_sampling)\n",
    "\n",
    "original_signal.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering values\n",
    "f_bands_N = config.f_bands_N         # number of frequency bands\n",
    "bandwidth = config.bandwidth         # bandwidth of incoming audio signal\n",
    "# vector holding center frequencies of all frequency bands\n",
    "frequency_bands = np.linspace(bandwidth[0], bandwidth[1], f_bands_N)\n",
    "samples = len(array_audio_signals[0].get_audio_signals()[:, 0])\n",
    "#filter_coefficients = np.zeros((f_bands_N, filter_order+1)) # might only be used for plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adaptive weights, calibration weights and filter coefficients\n",
    "adaptive_weights_matrix = adaptive_array_config_matrix(array_matrices[0])\n",
    "calibration_weights = load_calibration_weights(\n",
    "    0, config.rows*config.columns, config.f_bands_N)\n",
    "filter_coefficients = calculate_filter_coefficients(\n",
    "    f_sampling, frequency_bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!Process: 0 done!\n",
      "\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "Process: 0 done!\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "Process: 0 done!\n",
      "\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n",
      "Process: 0 done!\n",
      "Process: 0 done!\n",
      "Process: 0 done!Process: 0 done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Begin signal processing on the signals\n",
    "audio = listening_improved(array_audio_signals, array_matrices, config.theta_listen, config.phi_listen,\n",
    "                           adaptive_weights_matrix, calibration_weights, filter_coefficients, frequency_bands, f_sampling, samples, sub_arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'DictProxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2646370/2121044471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# play sound after signal processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplay_sound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_sampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2646370/3913170384.py\u001b[0m in \u001b[0;36mplay_sound\u001b[0;34m(sound_signal, f_sampling)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_sound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_sampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# plays sound, and writes audio to .wav file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscaled_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msound_signal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Scaled signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msounddevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for abs(): 'DictProxy'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# play sound after signal processing\n",
    "play_sound(audio, f_sampling)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('aw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ceee8c0ea4f82d14d9ad676ce2074c48a32eef0315b63026b3029e463704f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
